{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SALES PREDICTION USING ARIMA AND PROPHET FOR BRAZILIAN E-COMMERCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset was generously provided by Olist, the largest department store in Brazilian marketplaces. Olist connects small businesses from all over Brazil to channels without hassle and with a single contract. Those merchants are able to sell their products through the Olist Store and ship them directly to the customers using Olist logistics partners. See more on our website: www.olist.com\n",
    "\n",
    "After a customer purchases the product from Olist Store a seller gets notified to fulfill that order. Once the customer receives the product, or the estimated delivery date is due, the customer gets a satisfaction survey by email where he can give a note for the purchase experience and write down some comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is ARIMA model?**\n",
    "\n",
    "A. ARIMA(Auto Regressive Integrated Moving Average) is a combination of 2 models AR(Auto Regressive) & MA(Moving Average). It has 3 hyperparameters - P(auto regressive lags),d(order of differentiation),Q(moving avg.) which respectively comes from the AR, I & MA components. The AR part is correlation between prev & current time periods. To smooth out the noise, the MA part is used. The I part binds together the AR & MA parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“¤ IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statsmodels\n",
    "!pip install pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from scipy import stats\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from pylab import rcParams\n",
    "\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "from xgboost import  XGBRegressor\n",
    "\n",
    "# elimina os warnings das bibliotecas\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ’¾ CHECK OUT THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item = pd.read_csv(\"Documents/Mentoria_stack/dataset/olist_order_items_dataset.csv\")\n",
    "df_reviews = pd.read_csv(\"Documents/Mentoria_stack/dataset/olist_order_reviews_dataset.csv\")\n",
    "df_orders = pd.read_csv(\"Documents/Mentoria_stack/dataset/olist_orders_dataset.csv\")\n",
    "df_products = pd.read_csv(\"Documents/Mentoria_stack/dataset/olist_products_dataset.csv\")\n",
    "df_geolocation = pd.read_csv(\"Documents/Mentoria_stack/dataset/olist_geolocation_dataset.csv\")\n",
    "df_sellers = pd.read_csv(\"Documents/Mentoria_stack/dataset/olist_sellers_dataset.csv\")\n",
    "df_order_pay = pd.read_csv(\"Documents/Mentoria_stack/dataset/olist_order_payments_dataset.csv\")\n",
    "df_customers = pd.read_csv(\"Documents/Mentoria_stack/dataset/olist_customers_dataset.csv\")\n",
    "df_category = pd.read_csv(\"Documents/Mentoria_stack/dataset/product_category_name_translation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ALL IN ONE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all the tables in one dataframe\n",
    "df_train = df_orders.merge(df_item, on='order_id', how='left')\n",
    "df_train = df_train.merge(df_order_pay, on='order_id', how='outer', validate='m:m')\n",
    "df_train = df_train.merge(df_reviews, on='order_id', how='outer')\n",
    "df_train = df_train.merge(df_products, on='product_id', how='outer')\n",
    "df_train = df_train.merge(df_customers, on='customer_id', how='outer')\n",
    "df_train = df_train.merge(df_sellers, on='seller_id', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONVERT DATE COLUMNS TO TIMESTAMP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['order_purchase_time'] = pd.to_datetime(df_train['order_purchase_timestamp']).dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting attributes for purchase date - Date\n",
    "df_train['order_purchase_timestamp'] = pd.to_datetime(df_train['order_purchase_timestamp']).dt.date\n",
    "df_train['order_delivered_customer_date'] = pd.to_datetime(df_train['order_delivered_customer_date']).dt.date\n",
    "df_train['order_estimated_delivery_date'] = pd.to_datetime(df_train['order_estimated_delivery_date']).dt.date\n",
    "df_train['order_approved_at'] = pd.to_datetime(df_train['order_approved_at']).dt.date\n",
    "df_train['order_delivered_carrier_date'] = pd.to_datetime(df_train['order_delivered_carrier_date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting attributes for purchase date - Year and Month\n",
    "df_train['order_purchase_year'] = pd.to_datetime(df_train['order_purchase_timestamp']).dt.year\n",
    "df_train['order_purchase_month'] = pd.to_datetime(df_train['order_purchase_timestamp']).dt.month\n",
    "df_train['order_purchase_month_name'] = df_train['order_purchase_timestamp'].apply(lambda x: x.strftime('%b'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting attributes for purchase date - Day and Day of Week\n",
    "df_train['order_purchase_day'] = pd.to_datetime(df_train['order_purchase_timestamp']).apply(lambda x: x.day)\n",
    "df_train['order_purchase_dayofweek'] = pd.to_datetime(df_train['order_purchase_timestamp']).apply(lambda x: x.dayofweek)\n",
    "df_train['order_purchase_dayofweek_name'] = pd.to_datetime(df_train['order_purchase_timestamp']).dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['order_purchase_timestamp'] = pd.to_datetime(df_train['order_purchase_timestamp'])\n",
    "df_train['order_purchase_time'] = pd.to_datetime(df_train['order_purchase_time'],format='%H:%M:%S').dt.time\n",
    "df_train['order_delivered_customer_date'] = pd.to_datetime(df_train['order_delivered_customer_date'])\n",
    "df_train['order_estimated_delivery_date'] = pd.to_datetime(df_train['order_estimated_delivery_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_state=df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEAN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<iframe src=\"https://www.kaggle.com/embed/fekmea/preparation-olist-dataset/notebook?cellIds=10&kernelSessionId=80861728\" height=\"300\" style=\"margin: 0 auto; width: 100%; max-width: 950px;\" frameborder=\"0\" scrolling=\"auto\" title=\"Preparation Olist dataset\"></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum().sort_values(ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We may drop the review_comment_title column, as all values are null\n",
    "df_train.drop(['review_comment_title'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default review comment message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['review_comment_message'] = df_train['review_comment_message'].fillna('No message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_0 = df_train.shape[0]\n",
    "#Remove missing values with dropna\n",
    "df_train= df_train.dropna()\n",
    "df_train_1 = df_train.shape[0]\n",
    "print(f'{round(((df_train_0-df_train_1)/df_train_1)*100,2)}% nan values points were eliminated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting the histogram and normal probability plot\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.suptitle('Price Distributions', fontsize=22)\n",
    "plt.subplot(221)\n",
    "g = sns.histplot(df_train['price'], kde=True)\n",
    "g.set_title(\"Price Distributions\", fontsize=18)\n",
    "g.set_xlabel(\"Price Values\", fontsize=15)\n",
    "g.set_ylabel(\"Probability\", fontsize=15)\n",
    "\n",
    "plt.subplot(222)\n",
    "g1 = sns.histplot(np.log(df_train['price']), kde=True)\n",
    "g1.set_title(\"Price(LOG) Distributions\", fontsize=18)\n",
    "g1.set_xlabel(\"Price Values\", fontsize=15)\n",
    "g1.set_ylabel(\"Probability\", fontsize=15)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "\n",
    "plt.suptitle('Price Distribution Probability Plot', fontsize=22)\n",
    "\n",
    "plt.subplot(221)\n",
    "res = stats.probplot(df_train['price'], plot=plt, fit=True, rvalue=True);\n",
    "\n",
    "\n",
    "plt.subplot(222)\n",
    "res = stats.probplot(np.log(df_train['price']), plot=plt, fit=True, rvalue=True);\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Price Distribution:**\n",
    "Histogram of a sample from a right-skewed distribution â€“ it looks unimodal and skewed right.\n",
    "\n",
    "**Price Log Distribution:**\n",
    "Histogram of a sample from a normal distribution â€“ it looks fairly symmetric and unimodal.\n",
    "\n",
    "**Probability Plot - Price Distribution:**\n",
    "Normal probability plot of a sample from a right-skewed distribution â€“ it has an inverted C shape.\n",
    "\n",
    "**Probability Plot - Price Log Distribution:**\n",
    "Normal probability plot of a sample from a normal distribution â€“ it looks fairly straight, at least when the few large and small values are ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Check the Features Through the Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our current timestamps can be tricky to work with, so we'll be using the average daily price amount for that month, and we're using the start of each month as the timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['order_purchase_timestamp'].min(), df_train['order_purchase_timestamp'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.groupby('order_purchase_timestamp')['price'].sum().reset_index()\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Indexing with Time Series of Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=df_train.set_index('order_purchase_timestamp')\n",
    "df_train.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = df_train['price'].resample('MS').mean()\n",
    "sales2=sales[3:]\n",
    "sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Viewing Furniture Sales Time Series Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.plot(figsize=(15, 6))\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sell per month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine rolling statistics\n",
    "sales_mean = sales.rolling(window=12).mean() #window size 12 denotes 12 months, giving rolling mean at yearly level\n",
    "sales_std = sales.rolling(window=12).std()\n",
    "print(sales_mean,sales_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot rolling statistics\n",
    "plt.figure(figsize=(20,10))\n",
    "orig = plt.plot(sales, color='blue', label='Original')\n",
    "sales_mean = plt.plot(sales_mean, color='red', label='Rolling Mean')\n",
    "sales_std = plt.plot(sales_std, color='black', label='Rolling Std')\n",
    "plt.legend(loc='best')\n",
    "plt.title('Rolling Mean & Standard Deviation')\n",
    "plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro, vamos decompor a sÃ©rie pra avaliar tendÃªncia\n",
    "# Sazonalidade e resÃ­duo\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "resultado = seasonal_decompose(df_train)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))  \n",
    "fig = resultado.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste de estacionariedade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste de estacionariedade. \n",
    "# A hipÃ³tese nula Ã© que a sÃ©rie nÃ£o Ã© estacionÃ¡ria\n",
    "# Ou seja, se o p-valor for menor que 0,05, rejeitamos\n",
    "# que a sÃ©rie nÃ£o Ã© estacionÃ¡ria. Caso seja maior, nÃ£o podemos\n",
    "# descartar que a sÃ©rie nÃ£o Ã© estacionÃ¡ria\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "result=adfuller(df['producao'].dropna())\n",
    "print(f'Teste ADF:{result[0]}')\n",
    "print(f'p-valor:{result[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA Model for Time Series Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply one of the most used methods for forecasting time series, known as ARIMA, which stands Autoregressive Integrated Moving Average.\n",
    "\n",
    "ARIMA models are denoted with the ARIMA notation (p, d, q). These three parameters are responsible for the seasonality, trend and noise in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = d = q = range(0, 2)\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "seasonal_pdq = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
    "print('Examples of parameter combinations for Seasonal ARIMA...')\n",
    "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[2]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[3]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\") # specify to ignore warning messages\n",
    "\n",
    "for param in pdq:\n",
    "    for param_seasonal in seasonal_pdq:\n",
    "        try:\n",
    "            mod = sm.tsa.statespace.SARIMAX(sales,\n",
    "                                            order=param,\n",
    "                                            seasonal_order=param_seasonal,\n",
    "                                            #enforce_stationarity=False,\n",
    "                                            enforce_invertibility=False)\n",
    "\n",
    "            results = mod.fit()\n",
    "\n",
    "            print('ARIMA{}x{}12 - AIC:{}'.format(param, param_seasonal, results.aic))\n",
    "        except:\n",
    "            continue           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = sm.tsa.statespace.SARIMAX(sales2,\n",
    "                                order=(1, 1, 0),\n",
    "                                seasonal_order=(0, 1, 0, 12),\n",
    "                                enforce_invertibility=False)\n",
    "results = mod.fit(disp=False)\n",
    "print(results.summary().tables[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot_diagnostics(variable=0, lags=2, figsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A saÃ­da acima sugere que o SARIMAX (0, 1, 0) x (1, 1, 0, 12) produz o menor valor de AIC de 4.0. Portanto, devemos considerar isso como a melhor opÃ§Ã£o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjusting the ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pandas import DataFrame\n",
    "# fit model\n",
    "model = ARIMA(sales, order=(1,1,1))\n",
    "model_fit = model.fit()\n",
    "# summary of fit model\n",
    "print(model_fit.summary())\n",
    "# line plot of residuals\n",
    "residuals = DataFrame(model_fit.resid)\n",
    "residuals.plot()\n",
    "plt.show()\n",
    "# density plot of residuals\n",
    "residuals.plot(kind='kde')\n",
    "plt.show()\n",
    "# summary stats of residuals\n",
    "print(residuals.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Customer's State Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(35,14))\n",
    "\n",
    "plt.subplot(221)\n",
    "sns.set(font_scale=1.5) \n",
    "g2 = sns.boxplot(x='customer_state', y='price', \n",
    "                 data=df_train_state[df_train_state['price'] != -1])\n",
    "g2.set_title(\"Customer's State by Price\", fontsize=20)\n",
    "g2.set_xlabel(\"State\", fontsize=20)\n",
    "g2.set_ylabel(\"Price\", fontsize=20)\n",
    "g2.set_xticklabels(g2.get_xticklabels(),rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,14))\n",
    "df_train_state['price_log'] = np.log(df_train_state['price'])\n",
    "\n",
    "plt.subplot(221)\n",
    "sns.set(font_scale=1.5) \n",
    "g2 = sns.boxplot(x='customer_state', y='price_log', \n",
    "                 data=df_train_state[df_train_state['price'] != -1])\n",
    "g2.set_title(\"Customer's State by Price Log\", fontsize=20)\n",
    "g2.set_xlabel(\"State\", fontsize=20)\n",
    "g2.set_ylabel(\"Price Log\", fontsize=20)\n",
    "g2.set_xticklabels(g2.get_xticklabels(),rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,12))\n",
    "\n",
    "g = sns.countplot(x='customer_state', data=df_train_state, orient='h', order=df_train['customer_state'].value_counts().index)\n",
    "g.set_title(\"DISTRIBUIÃ‡ÃƒO DE CLIENTES POR ESTADO\", fontsize=20)\n",
    "g.set_xlabel(\"Estado\", fontsize=17)\n",
    "g.set_ylabel(\"Quantidade (%)\", fontsize=17)\n",
    "g.set_xticklabels(g.get_xticklabels(),rotation=90)\n",
    "sizes = []\n",
    "total=len(df_train_state)\n",
    "\n",
    "for p in g.patches:\n",
    "    height = p.get_height()\n",
    "    sizes.append(height)\n",
    "    g.text(p.get_x()+p.get_width()/2.,\n",
    "            height + 3,\n",
    "            '{:1.2f}%'.format(height/total*100),\n",
    "            ha=\"center\", fontsize=14) \n",
    "g.set_ylim(0, max(sizes) * 1.1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/letsdata/series-temporais-python/blob/main/series-temporais-python.ipynb"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c4b2e2b177025e3781112894bf8739cf5d0336ec369f5ec6c6310b21f5f1c4f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
